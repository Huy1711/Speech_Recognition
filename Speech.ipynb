{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcfa5E7u3fhb",
        "outputId": "dcb9810a-f7c9-4929-bc4f-315893472294"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "amng8WgN9T4h"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as idsp\n",
        "import pydub\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder = \"/content/sample_data/train\"\n",
        "split_train_folder = \"/content/sample_data/split_train\"\n",
        "test_folder = \"/content/sample_data/test\"\n",
        "split_test_folder = \"/content/sample_data/split_test\"\n",
        "mfccs_folder = \"/content/sample_data/mfccs\"\n",
        "\n",
        "os.mkdir(train_folder)\n",
        "os.mkdir(split_train_folder)\n",
        "os.mkdir(test_folder)\n",
        "os.mkdir(split_test_folder)\n",
        "os.mkdir(mfccs_folder)"
      ],
      "metadata": {
        "id": "_017gXsyTtDi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split audio files"
      ],
      "metadata": {
        "id": "Qgwomky48Jua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SoundSegment:\n",
        "    def __init__(self, start: float, end: float, label: str):\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "        self.label = label\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"({} - {}: {})\".format(self.start, self.end, self.label)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__str__()"
      ],
      "metadata": {
        "id": "A1BOeB013KzJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_to_folder(in_folder, out_folder):\n",
        "    files = os.listdir(in_folder)\n",
        "    file_names = [file[:-4] for file in files]\n",
        "    for file in file_names:\n",
        "        # read labels for that file\n",
        "        labels = []\n",
        "        with open(f\"{in_folder}/{file}.txt\", \"r\") as f:\n",
        "            for line in f:\n",
        "                if line.strip() == \"\":\n",
        "                    continue\n",
        "                start, stop, label = line.split(\"\\t\")\n",
        "                labels.append(SoundSegment(float(start), float(stop), label.strip()))\n",
        "\n",
        "        # chop each label into its own wav\n",
        "        for order, label in enumerate(labels):\n",
        "            audio = pydub.AudioSegment.from_wav(f\"{in_folder}/{file}.wav\")\n",
        "            audio = audio[int(label.start * 1000) : int(label.end * 1000)]\n",
        "            audio.export(\n",
        "                f\"{out_folder}/{label.label}_{file}_{order+1}.wav\", format=\"wav\"\n",
        "            )"
      ],
      "metadata": {
        "id": "y_gGlNxf3pvd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_to_folder(train_folder, split_train_folder)\n",
        "split_to_folder(test_folder, split_test_folder)"
      ],
      "metadata": {
        "id": "CEFOLI-DsGz0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MFCC "
      ],
      "metadata": {
        "id": "21ejjy3G8HC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sr = 22050\n",
        "\n",
        "def mfccs_extract(file):\n",
        "    sound, sr = librosa.load(f\"{split_train_folder}/{file}.wav\")\n",
        "    mfcc = librosa.feature.mfcc(y=sound, n_mfcc=13, sr=sr)\n",
        "    for i in range(mfcc.shape[1]):\n",
        "        mfcc[:,i] = mfcc[:,i] - np.min(mfcc[:,i])\n",
        "        mfcc[:,i] = mfcc[:,i]/(np.max(mfcc[:,i]) - np.min(mfcc[:,i]))\n",
        "    delta_mfcc = librosa.feature.delta(mfcc)\n",
        "    delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
        "    mfccs = np.concatenate((mfcc, delta_mfcc, delta2_mfcc))\n",
        "    return mfccs"
      ],
      "metadata": {
        "id": "WriDqjTx8EQ-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = os.listdir(split_train_folder)\n",
        "file_names = [file[:-4] for file in files]\n",
        "# print(file_names)\n",
        "\n",
        "for file in file_names:\n",
        "    mfccs = mfccs_extract(file)\n",
        "    np.savetxt(f\"{mfccs_folder}/{file}.txt\", mfccs, delimiter=\",\")"
      ],
      "metadata": {
        "id": "t5GflJ9S8FDZ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mfccs(file):\n",
        "    return np.loadtxt(f\"{mfccs_folder}/{file}.txt\", delimiter=\",\")"
      ],
      "metadata": {
        "id": "rXPFppI8_1tZ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_files = list(filter(lambda k: 'test' in k, file_names))\n",
        "file_names = list(filter(lambda k: 'test' not in k, file_names))\n",
        "\n",
        "A_files = list(filter(lambda k: 'A' in k, file_names))\n",
        "B_files = list(filter(lambda k: 'B' in k, file_names))\n",
        "len_files = list(filter(lambda k: 'len' in k, file_names))\n",
        "xuong_files = list(filter(lambda k: 'xuong' in k, file_names))\n",
        "trai_files = list(filter(lambda k: 'trai' in k, file_names))\n",
        "phai_files = list(filter(lambda k: 'phai' in k, file_names))\n",
        "ban_files = list(filter(lambda k: 'ban' in k, file_names))\n",
        "nhay_files = list(filter(lambda k: 'nhay' in k, file_names))\n",
        "sil_files = list(filter(lambda k: 'sil' in k, file_names))"
      ],
      "metadata": {
        "id": "lDxb4zppK9C4"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mfccs(label_files):\n",
        "    mfccs = []\n",
        "    for file in label_files:\n",
        "        mfccs.append(load_mfccs(file))\n",
        "    return mfccs"
      ],
      "metadata": {
        "id": "EcfFEXHvAfJj"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A_mfccs = load_mfccs(A_files)\n",
        "B_mfccs = load_mfccs(B_files)\n",
        "len_mfccs = load_mfccs(len_files)\n",
        "xuong_mfccs = load_mfccs(xuong_files)\n",
        "trai_mfccs = load_mfccs(trai_files)\n",
        "phai_mfccs = load_mfccs(phai_files)\n",
        "ban_mfccs = load_mfccs(ban_files)\n",
        "nhay_mfccs = load_mfccs(nhay_files)\n",
        "sil_mfccs = load_mfccs(sil_files)\n",
        "\n",
        "test_mfccs = load_mfccs(test_files)"
      ],
      "metadata": {
        "id": "GkL5DQKuT-YL"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DTW"
      ],
      "metadata": {
        "id": "3nbDUag-TKa4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "nkOp7k5O6MTL"
      },
      "outputs": [],
      "source": [
        "def dtw_cost(mfcc1, mfcc2):\n",
        "    D, wp = librosa.sequence.dtw(mfcc1, mfcc2, subseq = True, metric='euclidean')\n",
        "    return D[-1, -1]/wp.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def align_mfccs(label_mfccs):\n",
        "    template_mfcc = label_mfccs[0]\n",
        "    other_templates = label_mfccs[1:]\n",
        "    frame_num = template_mfcc.shape[1]\n",
        "    frame_lst = []\n",
        "    for i in range(frame_num):\n",
        "        frame = [template_mfcc[:, i]]\n",
        "        frame_lst.append(frame)\n",
        "\n",
        "    for mfcc in other_templates:\n",
        "        D, wp = librosa.sequence.dtw(template_mfcc, mfcc, subseq = True, metric='euclidean')\n",
        "        for i in wp:\n",
        "            frame_lst[i[0]].append(mfcc[:,i[1]])\n",
        "    return frame_lst"
      ],
      "metadata": {
        "id": "4iEFodx-XdbJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def average_templates(label_mfccs):\n",
        "    frame_lst = align_mfccs(label_mfccs)\n",
        "    frame_num = len(frame_lst)\n",
        "    average_mfcc = np.zeros(shape=(frame_num, 39))\n",
        "    for i in range(frame_num):\n",
        "        frame_average = np.array(frame_lst[i]).mean(axis=0)\n",
        "        average_mfcc[i] = frame_average\n",
        "    return average_mfcc.transpose()"
      ],
      "metadata": {
        "id": "ftfC1wwMJVHe"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A_template = average_templates(A_mfccs)\n",
        "B_template = average_templates(B_mfccs)\n",
        "len_template = average_templates(len_mfccs)\n",
        "xuong_template = average_templates(xuong_mfccs)\n",
        "trai_template = average_templates(trai_mfccs)\n",
        "phai_template = average_templates(phai_mfccs)\n",
        "nhay_template = average_templates(nhay_mfccs)\n",
        "ban_template = average_templates(ban_mfccs)\n",
        "sil_template = average_templates(sil_mfccs)"
      ],
      "metadata": {
        "id": "zERTvp0TLa2Y"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict = {\n",
        "  0: \"A\",\n",
        "  1: \"B\",\n",
        "  2: \"len\",\n",
        "  3: \"xuong\",\n",
        "  4: \"trai\",\n",
        "  5: \"phai\",\n",
        "  6: \"ban\",\n",
        "  7: \"nhay\",\n",
        "  8: \"sil\"\n",
        "}"
      ],
      "metadata": {
        "id": "ZeMSLG6m4X0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_num = 0\n",
        "sound_test = test_mfccs[test_num]\n",
        "\n",
        "def costs_compute(sound):\n",
        "    A_cost = dtw_cost(A_template, sound)\n",
        "    B_cost = dtw_cost(B_template, sound)\n",
        "    len_cost = dtw_cost(len_template, sound)\n",
        "    xuong_cost = dtw_cost(xuong_template, sound)\n",
        "    trai_cost = dtw_cost(trai_template, sound)\n",
        "    phai_cost = dtw_cost(phai_template, sound)\n",
        "    ban_cost = dtw_cost(ban_template, sound)\n",
        "    nhay_cost = dtw_cost(nhay_template, sound)\n",
        "    sil_cost = dtw_cost(sil_template, sound)\n",
        "    return [A_cost, B_cost, len_cost, xuong_cost, trai_cost, phai_cost, ban_cost, nhay_cost, sil_cost]\n",
        "\n",
        "costs = costs_compute(sound_test)\n",
        "result = dict.get(np.array(costs).argmin())\n",
        "print('result = \\\"{}\\\"'.format(result))\n",
        "print('filename = \\\"{}\\\"'.format(test_files[test_num].split('_')[0]))\n",
        "print(\"Correct =  {}\".format(result == test_files[test_num].split('_')[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RH_N8Ol_rOO",
        "outputId": "55a58594-bcaf-43d2-f2a0-5cde3390836c"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result = \"trai\"\n",
            "filename = \"trai\"\n",
            "Correct =  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_len = len(test_mfccs)\n",
        "correct = 0\n",
        "\n",
        "for i in range(test_len):\n",
        "    sound = test_mfccs[i]\n",
        "    costs = costs_compute(sound)\n",
        "    result = dict.get(np.array(costs).argmin())\n",
        "    label = test_files[i].split('_')[0]\n",
        "    if(result == label):\n",
        "        correct += 1\n",
        "\n",
        "print(\"Accuracy: {}/{}\".format(correct, test_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtbgI6QEhXfX",
        "outputId": "1096a8a2-c873-45ef-ad63-dac418c3f3fe"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 120/121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HMM"
      ],
      "metadata": {
        "id": "jfQmHKEDU-3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hmmlearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIE1EBHtcsty",
        "outputId": "ff23fdbc-e4ca-466e-9cbf-35efd2349c9e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.2.7-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (129 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 129 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from hmmlearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from hmmlearn) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.7/dist-packages (from hmmlearn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->hmmlearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->hmmlearn) (3.1.0)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hmmlearn import hmm\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython import display\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "AQ-7NW7HcPNc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mfcc(y, sr):\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    delta = librosa.feature.delta(mfcc)\n",
        "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
        "    return np.vstack((mfcc, delta, delta2)).T"
      ],
      "metadata": {
        "id": "Pw5U3NXai22-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buildDataSet(folder):\n",
        "    dataset = {}\n",
        "    files = os.listdir(folder)\n",
        "    file_names = [file[:-4] for file in files]\n",
        "    for file in file_names:\n",
        "        y, sr = librosa.load(f\"{folder}/{file}.wav\")\n",
        "        mfccs = get_mfcc(y, sr)\n",
        "        label = file.split('_')[0]\n",
        "        if label not in dataset.keys():\n",
        "            dataset[label] = []\n",
        "            dataset[label].append(mfccs)\n",
        "        else:\n",
        "            exist_feature = dataset[label]\n",
        "            exist_feature.append(mfccs)\n",
        "            dataset[label] = exist_feature\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "oReHHmmlagNk"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_GMMHMM(dataset):\n",
        "    GMMHMM_Models = {}\n",
        "    states_num = 5\n",
        "    GMM_mix_num = 3\n",
        "    tmp_p = 1.0/(states_num-2)\n",
        "    transmatPrior = np.array([[tmp_p, tmp_p, tmp_p, 0 ,0], \\\n",
        "                               [0, tmp_p, tmp_p, tmp_p , 0], \\\n",
        "                               [0, 0, tmp_p, tmp_p, tmp_p], \\\n",
        "                               [0, 0, 0, 0.5, 0.5], \\\n",
        "                               [0, 0, 0, 0, 1]],dtype=np.float)\n",
        "\n",
        "    startprobPrior = np.array([0.5, 0.5, 0, 0, 0],dtype=np.float)\n",
        "\n",
        "    for label in dataset.keys():\n",
        "        model = hmm.GMMHMM(n_components=states_num, n_mix=GMM_mix_num, \\\n",
        "                           transmat_prior=transmatPrior, startprob_prior=startprobPrior, \\\n",
        "                           covariance_type='diag', n_iter=10)\n",
        "        trainData = dataset[label]\n",
        "        length = np.zeros([len(trainData), ], dtype=np.int)\n",
        "        for m in range(len(trainData)):\n",
        "            length[m] = trainData[m].shape[0]\n",
        "        trainData = np.vstack(trainData)\n",
        "        model.fit(trainData, lengths=length)  # get optimal parameters\n",
        "        GMMHMM_Models[label] = model\n",
        "    return GMMHMM_Models"
      ],
      "metadata": {
        "id": "hUKnvC_VfJqd"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = buildDataSet(split_train_folder)\n",
        "hmmModels = train_GMMHMM(train_dataset)"
      ],
      "metadata": {
        "id": "tHh7Ta5kfWup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testDataSet = buildDataSet(split_test_folder)"
      ],
      "metadata": {
        "id": "dcZ5eml2rjdm"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict = {}\n",
        "for i, k in enumerate(testDataSet.keys()):\n",
        "    dict[i] = k\n",
        "\n",
        "dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zznUy6se4xeV",
        "outputId": "b60d1e8b-f7d8-401b-c0df-907f3a06cdf8"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'trai',\n",
              " 1: 'sil',\n",
              " 2: 'xuong',\n",
              " 3: 'len',\n",
              " 4: 'A',\n",
              " 5: 'phai',\n",
              " 6: 'B',\n",
              " 7: 'ban',\n",
              " 8: 'nhay'}"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_true = []\n",
        "y_preds = []\n",
        "\n",
        "for label in testDataSet.keys():\n",
        "    for mfcc in testDataSet[label]:\n",
        "        scores = [hmmModels[label].score(mfcc) for label in testDataSet.keys()]\n",
        "        preds = np.argmax(scores)\n",
        "        y_true.append(label)\n",
        "        y_preds.append(dict.get(preds))\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_preds)\n",
        "print(\"Accuracy Score: {}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlO0stBOzKug",
        "outputId": "097efe6d-4d04-4b1e-f87d-77ed23a63de5"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 1.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Qgwomky48Jua"
      ],
      "name": "Speech.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}